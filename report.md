# YOLO Training отчет

  

Примечание: Все оригинальные графики можно найти по пути `statistics` в папках v1, v2, v3

  

## 1. Аннотирование данных

  

Скриптом `extract_frames.py` извлек кадры из видео, со значением **fps = 1**

  

Далее загрузил полученные фреймы на roboflow, произвел аннотацию bbox и 6 классов:

  

- `cutlery_basket` - корзина для столовых приборов

  

- `foodboard` - разделочная доска

  

- `plate` - тарелка

  

- `soup_bowl` - суповая тарелка

  

- `teacup` - чайная чашка

  

- `teapot` - чайник

  

создал размеченный датасет под YOLOv11 модель. Далее работал исключительно с этим датасетом.

Возможности улучшения: Переразметка датасета, или дополнение классов, есть проблемные места по типу teacup. Признаю, разметка была относительно не идеальна.

  

## Этап 1. Первичное обучение модели | v1

Сложности: Низкая начальная производительность из-за отсутствия предобученных данных для специфических классов.

  

Подход: Использование базовых весов ultralytics, слабой аугментации

### Параметры обучения модели

  

- Epochs: 50 — выбран для достижения сходимости модели.

- Batch: 16 — обеспечивает баланс между использованием GPU и стабильностью обучения.

- ImgSz: 640 — стандартное разрешение для YOLO, обеспечивающее хорошее качество детекции.

- Device: mps — использование GPU на macOS для ускорения вычислений.

- Optimizer: auto — автоматический выбор оптимизатора для адаптации к данным.

- Pretrained: true — использование предобученных весов для ускорения обучения и повышения точности.

- Learning Rate: начальное значение 0.01 с постепенным уменьшением, что помогает избежать переобучения.

- Augmentation: включены параметры (hsv_h, hsv_s, translate, scale, fliplr), чтобы повысить обобщающую способность модели.

  

### Графики метрик

  

#### Потери

* **Train/box_loss**, **train/cls_loss**, **train/dfl_loss**: Постепенное снижение с 3.6, 4.7 и 4.2 до 0.54, 0.89 и 1.16 соответственно к 50-й эпохе, что указывает на успешное обучение.

* **Val/box_loss**, **val/cls_loss**, **val/dfl_loss**: Снижение с 3.08, 4.74 и 4.16 до 0.52, 0.84 и 1.12, демонстрируя хорошую обобщающую способность.

  

#### Метрики качетва

* **Precision(B)**: Увеличение с 0 до 0.734 к 50-й эпохе, что отражает рост точности предсказаний.

* **Recall(B)**: Рост с 0 до 0.866, показывающий улучшение охвата объектов.

* **mAP50(B)**: Увеличение с 0 до 0.818, что указывает на высокую точность при IoU=0.5

* **mAP50-95(B)**: Рост с 0 до 0.720, демонстрирующий стабильность на разных уровнях IoU.

  

### Анализ ошибок

  

- На ранних эпохах (1-9) наблюдается нулевая точность и полнота, что связано с начальной стадией обучения и недостаточной адаптацией модели.

- Матрица ошибок показывает высокую диагональную точность (например, 0.92 для cutlery_basket), но есть путаница между классами (например, 0.43 cutlery_basket предсказано как background), что требует улучшения разделения классов.

- F1-Confidence кривая показывает пиковые значения около 0.79 для всех классов при уверенности 0.205, что указывает на оптимальный порог детекции.

### Выводы

  

Модель демонстрирует хорошую производительность с mAP50 0.818 и mAP50-95 0.720, что делает её пригодной для задач детекции кухонной утвари. Основные улучшения можно достичь за счёт:

- Увеличения объёма данных для миноритарных классов (например, teacup и teapot)

- Настройки порога уверенности для минимизации ложных срабатываний.

- Дополнительной аугментации для улучшения разделения схожих классов.

  

## Этап 2. Вторая итерация обучения | v2

  

Сложности: Снижение precision на некоторых этапах из-за адаптации весов.

Подход: Сохранение предобученных весов и оптимизация аугментации.

### Параметры обучения и причины выбора

  

Модель обучалась с использованием тех же весов runs/detect/train3/weights/best.pt с обновлёнными параметрами:

  

- **Epochs**: 30 — уменьшено с 50 до 30 для оптимизации времени обучения при сохранении сходимости.

- **Batch**: 16 — сохранён для баланса между производительностью и использованием GPU.

- **ImgSz**: 640 — сохранено для согласованности с первой моделью.

- **Device**: mps — сохранён для ускорения на macOS.

- **Optimizer**: auto — оставлен для адаптации к данным.

- **Pretrained**: true — использование тех же предобученных весов для ускорения.

- **Learning Rate**: начальное значение 0.01 с постепенным уменьшением, что помогает избежать переобучения.

- **Augmentation**: параметры (hsv_h, hsv_s, hsv_v, translate, scale, fliplr) сохранены, но с меньшей интенсивностью (например, degrees: 0.0, shear: 0.0), так как была произведена ручная аугментация train/ (shear, degrees, шумы и изменение цвета, корректировка bbox)

  

Выбор параметров направлен на доработку модели с акцентом на эффективность и стабильность.

  

### Графики метрик

  

#### Потери

- **Train/box_loss**, **train/cls_loss**, **train/dfl_loss**: Снижение с 1.31685, 1.30204 и 1.69848 до 0.50416, 0.59713 и 1.02969 соответственно к 30-й эпохе, что указывает на успешное обучение.

- **Val/box_loss**, **val/cls_loss**, **val/dfl_loss**: Снижение с 0.85721, 1.09055 и 1.30018 до 0.31849, 0.52101 и 0.88793, демонстрируя улучшение обобщающей способности.

  

#### Метрики качества.

- **Precision(B)**: Рост с 0.82213 до 0.74813, показывающий стабильную, но чуть меньшую точность по сравнению с первой моделью.

- **Recall(B)**: Увеличение с 0.77926 до 0.84276, что отражает улучшение охвата объектов.

- **mAP50(B)**: Рост с 0.8134 до 0.84798, что указывает на высокую точность при IoU=0.5

- **mAP50-95(B)**: Увеличение с 0.61549 до 0.79054, демонстрируя значительное улучшение на разных уровнях IoU.

  

### Анализ ошибок

  

- На ранних эпохах (1-5) наблюдается высокая начальная точность (0.82213), что связано с использованием предобученных весов, но затем происходит временное снижение (до 0.62347 на 5-й эпохе), что может указывать на адаптацию модели.

- Матрица ошибок, вероятно, показывает улучшение разделения классов, так как mAP50-95 вырос по сравнению с первой моделью.

- F1-Confidence кривая, вероятно, достигает пика при уверенности около 0.75, что соответствует оптимальному порогу детекции.

### Выводы

Вторая модель демонстрирует улучшение по сравнению с первой, особенно в mAP50-95 (0.79054 против 0.720), что делает её более надёжной для детекции с различными порогами IoU. Уменьшение числа эпох до 30 не ухудшило результаты, что подтверждает эффективность оптимизации. Дальнейшие действия:

- Дополнительная аугментация для миноритарных классов (например, teacup).

- Тестирование с увеличением batch для потенциального роста производительности.

  

## Этап 3. Финальное обучение | v3

  

Сложности: Колебания presicion на ранних этапах.

Подход: Увеличение эпох и настройка скорости обучения.

  

### Параметры обучения модели

- **Epochs**: 75 — увеличено для достижения максимальной сходимости.

- **Batch**: 12 — уменьшено для оптимизации использования GPU.

- **ImgSz**: 640 — сохранено для согласованности.

- **Device**: mps — сохранено для работы на macOS.

- **Optimizer**: auto — адаптация к данным.

- **Pretrained**: true — использование предобученных весов.

- **Learning Rate**: начальное значение 0.008 с постепенным уменьшением (lrf: 0.01), что обеспечивает плавную сходимость.

- **Augmentation**: параметры (hsv_h: 0.015, hsv_s: 0.7, hsv_v: 0.4, translate: 0.1, scale: 0.5, fliplr: 0.5) выбраны для умеренного разнообразия без сильного искажения данных.

- **Cos_lr**: false — линейное снижение скорости обучения вместо косинусного.

- **Close_mosaic**: 10 — отключение мозаики на поздних этапах для фокусировки на деталях.

  

Выбор параметров направлен на баланс между точностью и вычислительными ресурсами.

  

### Графики метрик

#### Потери

- **Train/box_loss**, **train/cls_loss**, **train/dfl_loss**: Снижение с 0.77801, 0.76045 и 1.18074 до 0.33882, 0.38431 и 0.90401 соответственно к 75-й эпохе, указывая на стабильное обучение.

- **Val/box_loss**, **val/cls_loss**, **val/dfl_loss**: Уменьшение с 0.43545, 0.58015 и 0.95299 до 0.2173, 0.36777 и 0.82262, демонстрируя улучшение обобщающей способности

  

#### Метрики качества

- **Precision(B)**: Увеличение с 0.69933 до 0.75338, показывая стабильный рост точности.

- **Recall(B)**: Рост с 0.84816 до 0.97731, что отражает значительное улучшение охвата.

- **mAP50(B)**: Увеличение с 0.84384 до 0.88623, указывая на высокую точность при IoU=0.5.

- **mAP50-95(B)**: Рост с 0.75336 до 0.86243, демонстрируя значительное улучшение на разных уровнях IoU.

  

### Анализ ошибок

  

- На ранних эпохах (1-5) наблюдается колебание precision (0.69933 до 0.71637), что связано с адаптацией весов, но затем модель стабилизируется.

- Матрица ошибок, вероятно, показывает улучшение разделения классов, так как mAP50-95 вырос по сравнению с предыдущими моделями.

- F1-Confidence кривая, вероятно, достигает пика при уверенности около 0.75, что соответствует оптимальному порогу детекции.

  

### Выводы

Третья модель демонстрирует лучший результат среди всех, с mAP50-95 0.86243 на 75-й эпохе, что превосходит предыдущие модели. Увеличение числа эпох до 75 и оптимизация параметров аугментации способствовали улучшению метрик. Интересный факт: recall достигла почти 98% к концу обучения, что указывает на высокую способность модели обнаруживать объекты даже в сложных условиях.

  

## Итоговые выводы.

  

Модель достигла высокого уровня производительности с нуля и практически готова к практическому применению с возможностью дальнейшей оптимизации.

  

## Приложения

  

Видео работы модели: `https://disk.yandex.ru/d/pFvJaCiWfrRYug`

  

# UPDATED (26/05/2025 00:00):

  

## Этап 4. Прерванное обучение | V4 (без метрик)

  

Произвел работу по повторной аннотации датасета, более подробная разметка на кадрах, особенно с проблематичными классами: teacup, soup_bowl, teapot. Была произведена ручная аугментация объектов, "псевдо-увеличение" датасета. А также переданы параметры аугментации в параметры обучения модели.

  

### Параметры обучения (аналогичны предыдущей модели v3)

  

- **Epochs**: 75 — увеличено для достижения максимальной сходимости.

- **Batch**: 12 — уменьшено для оптимизации использования GPU.

- **ImgSz**: 640 — сохранено для согласованности.

- **Device**: mps — сохранено для работы на macOS.

- **Optimizer**: auto — адаптация к данным.

- **Pretrained**: true — использование предобученных весов.

- **Learning Rate**: начальное значение 0.008 с постепенным уменьшением (lrf: 0.01), что обеспечивает плавную сходимость.

- **Augmentation**: параметры (hsv_h: 0.015, hsv_s: 0.7, hsv_v: 0.4, translate: 0.1, scale: 0.5, fliplr: 0.5) выбраны для умеренного разнообразия без сильного искажения данных.

- **Cos_lr**: false — линейное снижение скорости обучения вместо косинусного.

- **Close_mosaic**: 10 — отключение мозаики на поздних этапах для фокусировки на деталях.

  
  

### Результаты работы

  

Где то спустя час, на ~25 эпохе произошла непредвиденная ошибка. Сохраненная модель по результатам распознает подробно классы: Plate (2 штуки на фреймах), soup_bowl (2-3 шт на фреймах), все также подробно распознаются: foodboard, cutlery_basket.

  

- По mAP на эпохе 20 удалось добиться показателя 0.93, хороший прирост за 20 эпох, остальные метрики немного подросли (см. ниже), эксперименты продолжаются.

  

## Этап 5. Заключительный | v5

  

Все тот же новый аннотированный датасет, но уже с меньшей аугментацией.

  

### Параметры обучения
- **Epochs**: 30 — достаточно для сходимости.
- **Batch**: 8 — оптимизация для GPU.
- **ImgSz**: 512 — уменьшено для производительности.    
- **Device**: mps — работа на macOS.
- **Optimizer**: auto — адаптация к данным.
- **Pretrained**: true — использование предобученных весов.
- **Learning Rate**: начальное 0.01 (lrf: 0.01) с тремя эпохами разогрева.
- **Augmentation**: минимально (hsv_h: 0.015, hsv_s: 0.7, hsv_v: 0.4, fliplr: 0.5), без сильных искажений.
- **Close_mosaic**: 10 — отключение мозаики на поздних этапах.

### Графики метрик
#### Потери (Loss)

- **Train/box_loss**, **train/cls_loss**, **train/dfl_loss**: Снижение с 0.88264, 0.5433, 1.1024 до 0.56667, 0.40423, 0.97628 к 30-й эпохе.
- **Val/box_loss**, **val/cls_loss**, **val/dfl_loss**: Уменьшение с 0.69839, 0.48989, 1.0433 до 0.58582, 0.45074, 0.98999.
#### Метрики качества
- **Precision(B)**: с 0.89457 до 0.87235.
- **Recall(B)**: с 0.95391 до 0.97799.
- **mAP50(B)**: с 0.9636 до 0.96242.
- **mAP50-95(B)**: с 0.80908 до 0.83509.

### Выводы
#### Анализ ошибок

- Precision колеблется (0.89457 до 0.87235), что может указывать на переобучение.
- Recall улучшился (0.95391 до 0.97799), демонстрируя лучшую детекцию объектов.
- mAP50-95 стабильно растет, что подтверждает обобщающую способность.

#### Выводы

Модель достигла mAP50-95 0.83509 на 30-й эпохе, показывая хорошие результаты. Интересный факт: recall достиг 97.8% к концу, указывая на высокую чувствительность. 

## Итог

Считаю эксперимент вполне удачным, наблюдаются зоны роста, распознавание классов teacup все еще не идеально, также есть данные, указывающие на высокую чувствительность. Модель способна к распознаванию и работе, с постепенным дообучением и устранением болезненных зон.

Потраченное время: ~16-20 часов, включая обучение модели.
